{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Assignment - Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (p.198, Chap.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We now review k-fold cross-validation.\n",
    "(a) Explain how k-fold cross-validation is implemented.\n",
    "(b) What are the advantages and disadvantages of k-fold crossvalidation relative to:\n",
    "i. The validation set approach?\n",
    "ii. LOOCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K fold cross validation is randomly divides the dataset into k number of equivalent groups. The first fold is kept for testing and the model is trained on k-1 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages:\n",
    "* Reduced bias\n",
    "* The variance of the resulting estimate is reduced as k increases\n",
    "* Comparatively easy to implement\n",
    "* Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disadvantages:\n",
    "* The training algorithm is computationally intensive\n",
    "* the validation set error rate may tend to overestimate the test error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 8 (p.200, Chap.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. what is n and what is p? Write out the model\n",
    "used to generate the data in equation form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(200)\n",
    "y = rnorm(100)\n",
    "x = rnorm(100)\n",
    "y = x - 2 * x^2 + rnorm(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Create a scatterplot of X against Y . Comment on what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nSBDwP3XsPsL4cFVTAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  Set a random seed, and then compute the LOOCV errors that\n",
    "result from fitting the following four models using least squares.\n",
    "i. Y = β0 + β1X +\n",
    "ii. Y = β0 + β1X + β2X2 +\n",
    "iii. Y = β0 + β1X + β2X2 + β3X3 +\n",
    "iv. Y = β0 + β1X + β2X2 + β3X3 + β4X4 + \n",
    "\n",
    "Note you may find it helpful to use the data.frame() function\n",
    "to create a single data set containing both X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/dwijayaweera/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'boot' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\dwijayaweera\\AppData\\Local\\Temp\\RtmpekL8CQ\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'boot' was built under R version 3.6.2\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3.81541843866053</li>\n",
       "\t<li>3.8139215446467</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3.81541843866053\n",
       "\\item 3.8139215446467\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3.81541843866053\n",
       "2. 3.8139215446467\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3.815418 3.813922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "install.packages(\"boot\")\n",
    "library(boot)\n",
    "Data = data.frame(x, y)\n",
    "set.seed(10)\n",
    "\n",
    "glm.fit = glm(y ~ x)\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.10128843851768</li>\n",
       "\t<li>1.10095892712426</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.10128843851768\n",
       "\\item 1.10095892712426\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.10128843851768\n",
       "2. 1.10095892712426\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.101288 1.100959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 2))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.1096088732873</li>\n",
       "\t<li>1.10920803362265</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.1096088732873\n",
       "\\item 1.10920803362265\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.1096088732873\n",
       "2. 1.10920803362265\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.109609 1.109208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 3))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.13265482227176</li>\n",
       "\t<li>1.13203415773006</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.13265482227176\n",
       "\\item 1.13203415773006\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.13265482227176\n",
       "2. 1.13203415773006\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.132655 1.132034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 4))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Repeat (c) using another random seed, and report your results.\n",
    "Are your results the same as what you got in (c)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3.81541843866053</li>\n",
       "\t<li>3.8139215446467</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3.81541843866053\n",
       "\\item 3.8139215446467\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3.81541843866053\n",
       "2. 3.8139215446467\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3.815418 3.813922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(200)\n",
    "\n",
    "glm.fit = glm(y ~ x)\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.10128843851768</li>\n",
       "\t<li>1.10095892712426</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.10128843851768\n",
       "\\item 1.10095892712426\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.10128843851768\n",
       "2. 1.10095892712426\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.101288 1.100959"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 2))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.1096088732873</li>\n",
       "\t<li>1.10920803362265</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.1096088732873\n",
       "\\item 1.10920803362265\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.1096088732873\n",
       "2. 1.10920803362265\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.109609 1.109208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 3))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1.13265482227176</li>\n",
       "\t<li>1.13203415773006</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1.13265482227176\n",
       "\\item 1.13203415773006\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1.13265482227176\n",
       "2. 1.13203415773006\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1.132655 1.132034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(y ~ poly(x, 4))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It was the same. Yes, because it is the same data set except for the seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Which of the models in (c) had the smallest LOOCV error? Is\n",
    "this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glm.fit = glm(y ~ poly(x, 4))\n",
    "cv.glm(Data, glm.fit)$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using\n",
    "least squares. Do these results agree with the conclusions drawn\n",
    "based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ poly(x, 4))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-2.64365  -0.64356   0.00863   0.60774   3.10084  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  -1.4110     0.1039 -13.582   <2e-16 ***\n",
       "poly(x, 4)1  12.5920     1.0388  12.121   <2e-16 ***\n",
       "poly(x, 4)2 -15.7694     1.0388 -15.180   <2e-16 ***\n",
       "poly(x, 4)3   0.7248     1.0388   0.698    0.487    \n",
       "poly(x, 4)4  -0.8165     1.0388  -0.786    0.434    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 1.079189)\n",
       "\n",
       "    Null deviance: 510.95  on 99  degrees of freedom\n",
       "Residual deviance: 102.52  on 95  degrees of freedom\n",
       "AIC: 298.28\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(glm.fit)\n",
    "\n",
    "#p-values show statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (p.259, Chap.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform best subset, forward stepwise, and backward stepwise\n",
    "selection on a single data set. For each approach, we obtain p + 1\n",
    "models, containing 0, 1, 2,...,p predictors. Explain your answers:\n",
    "\n",
    "(a) Which of the three models with k predictors has the smallest\n",
    "training RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Which of the three models with k predictors has the smallest\n",
    "test RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best subset selection can have the lowest RSS compared to other two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) True or False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9 (p.263, Chap.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this exercise, we will predict the number of applications received\n",
    "using the other variables in the College data set.\n",
    "(a) Split the data set into a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ISLR' was built under R version 3.6.2\""
     ]
    }
   ],
   "source": [
    "library(ISLR)\n",
    "\n",
    "train.size = dim(College)[1] / 2\n",
    "train = sample(1:dim(College)[1], train.size)\n",
    "test = -train\n",
    "College.train = College[train, ]\n",
    "College.test = College[test, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a linear model using least squares on the training set, and\n",
    "report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1143796.35901653"
      ],
      "text/latex": [
       "1143796.35901653"
      ],
      "text/markdown": [
       "1143796.35901653"
      ],
      "text/plain": [
       "[1] 1143796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit = lm(Apps~., data=College.train)\n",
    "lm.pred = predict(lm.fit, College.test)\n",
    "mean((College.test[, \"Apps\"] - lm.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Fit a ridge regression model on the training set, with λ chosen\n",
    "by cross-validation. R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/dwijayaweera/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'glmnet' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"cannot remove prior installation of package 'glmnet'\"Warning message in file.copy(savedcopy, lib, recursive = TRUE):\n",
      "\"problem copying C:\\Users\\dwijayaweera\\Documents\\R\\win-library\\3.6\\00LOCK\\glmnet\\libs\\x64\\glmnet.dll to C:\\Users\\dwijayaweera\\Documents\\R\\win-library\\3.6\\glmnet\\libs\\x64\\glmnet.dll: Permission denied\"Warning message:\n",
      "\"restored 'glmnet'\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\dwijayaweera\\AppData\\Local\\Temp\\RtmpekL8CQ\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'glmnet' was built under R version 3.6.2\"Loading required package: Matrix\n",
      "Warning message:\n",
      "\"package 'Matrix' was built under R version 3.6.2\"Loaded glmnet 3.0-2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"glmnet\")\n",
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.01"
      ],
      "text/latex": [
       "0.01"
      ],
      "text/markdown": [
       "0.01"
      ],
      "text/plain": [
       "[1] 0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.mat = model.matrix(Apps~., data=College.train)\n",
    "test.mat = model.matrix(Apps~., data=College.test)\n",
    "grid = 10 ^ seq(4, -2, length=100)\n",
    "mod.ridge = cv.glmnet(train.mat, College.train[, \"Apps\"], alpha=0, lambda=grid, thresh=1e-12)\n",
    "lambda.best = mod.ridge$lambda.min\n",
    "lambda.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1143769.65155509"
      ],
      "text/latex": [
       "1143769.65155509"
      ],
      "text/markdown": [
       "1143769.65155509"
      ],
      "text/plain": [
       "[1] 1143770"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.pred = predict(mod.ridge, new=test.mat, s=lambda.best)\n",
    "mean((College.test[, \"Apps\"] - ridge.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Fit a lasso model on the training set, with λ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "86.9749002617783"
      ],
      "text/latex": [
       "86.9749002617783"
      ],
      "text/markdown": [
       "86.9749002617783"
      ],
      "text/plain": [
       "[1] 86.9749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.lasso = cv.glmnet(train.mat, College.train[, \"Apps\"], alpha=1, lambda=grid, thresh=1e-12)\n",
    "lambda.best = mod.lasso$lambda.min\n",
    "lambda.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1178534.8002484"
      ],
      "text/latex": [
       "1178534.8002484"
      ],
      "text/markdown": [
       "1178534.8002484"
      ],
      "text/plain": [
       "[1] 1178535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso.pred = predict(mod.lasso, new=test.mat, s=lambda.best)\n",
    "mean((College.test[, \"Apps\"] - lasso.pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value\n",
    "of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much\n",
    "difference among the test errors resulting from these five approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lasso reduces the F.Undergrad and Books variables to zero and shrinks coefficients of other variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 9 (p.299, Chap.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question uses the variables dis (the weighted mean of distances\n",
    "to five Boston employment centers) and nox (nitrogen oxides concentration in parts per 10 million) from the Boston data. We will treat\n",
    "dis as the predictor and nox as the response.\n",
    "(a) Use the poly() function to fit a cubic polynomial regression to\n",
    "predict nox using dis. Report the regression output, and plot\n",
    "the resulting data and polynomial fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MASS' was built under R version 3.6.2\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = nox ~ poly(dis, 3), data = Boston)\n",
       "\n",
       "Residuals:\n",
       "      Min        1Q    Median        3Q       Max \n",
       "-0.121130 -0.040619 -0.009738  0.023385  0.194904 \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)    0.554695   0.002759 201.021  < 2e-16 ***\n",
       "poly(dis, 3)1 -2.003096   0.062071 -32.271  < 2e-16 ***\n",
       "poly(dis, 3)2  0.856330   0.062071  13.796  < 2e-16 ***\n",
       "poly(dis, 3)3 -0.318049   0.062071  -5.124 4.27e-07 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.06207 on 502 degrees of freedom\n",
       "Multiple R-squared:  0.7148,\tAdjusted R-squared:  0.7131 \n",
       "F-statistic: 419.3 on 3 and 502 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "lm.fit = lm(nox ~ poly(dis, 3), data = Boston)\n",
    "summary(lm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Plot the polynomial fits for a range of different polynomial\n",
    "degrees (say, from 1 to 10), and report the associated residual\n",
    "sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Perform cross-validation or another approach to select the optimal degree for the polynomial, and explain your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#using 10 fold k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nggBCggBCggBCggD/AZtVlgzNiIEIAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "all.deltas = rep(NA, 10)\n",
    "for (i in 1:10) {\n",
    "    glm.fit = glm(nox ~ poly(dis, i), data = Boston)\n",
    "    all.deltas[i] = cv.glm(Boston, glm.fit, K = 10)$delta[2]\n",
    "}\n",
    "plot(1:10, all.deltas, xlab = \"Degree\", ylab = \"CV error\", type = \"l\", pch = 20, \n",
    "    lwd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Use the bs() function to fit a regression spline to predict nox\n",
    "using dis. Report the output for the fit using four degrees of\n",
    "freedom. How did you choose the knots? Plot the resulting fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = nox ~ bs(dis, df = 4, knots = c(4, 7, 11)), data = Boston)\n",
       "\n",
       "Residuals:\n",
       "      Min        1Q    Median        3Q       Max \n",
       "-0.124567 -0.040355 -0.008702  0.024740  0.192920 \n",
       "\n",
       "Coefficients:\n",
       "                                      Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)                            0.73926    0.01331  55.537  < 2e-16 ***\n",
       "bs(dis, df = 4, knots = c(4, 7, 11))1 -0.08861    0.02504  -3.539  0.00044 ***\n",
       "bs(dis, df = 4, knots = c(4, 7, 11))2 -0.31341    0.01680 -18.658  < 2e-16 ***\n",
       "bs(dis, df = 4, knots = c(4, 7, 11))3 -0.26618    0.03147  -8.459 3.00e-16 ***\n",
       "bs(dis, df = 4, knots = c(4, 7, 11))4 -0.39802    0.04647  -8.565  < 2e-16 ***\n",
       "bs(dis, df = 4, knots = c(4, 7, 11))5 -0.25681    0.09001  -2.853  0.00451 ** \n",
       "bs(dis, df = 4, knots = c(4, 7, 11))6 -0.32926    0.06327  -5.204 2.85e-07 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.06185 on 499 degrees of freedom\n",
       "Multiple R-squared:  0.7185,\tAdjusted R-squared:  0.7151 \n",
       "F-statistic: 212.3 on 6 and 499 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(splines)\n",
    "sp.fit = lm(nox ~ bs(dis, df = 4, knots = c(4, 7, 11)), data = Boston)\n",
    "summary(sp.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Now fit a regression spline for a range of degrees of freedom, and\n",
    "plot the resulting fits and report the resulting RSS. Describe the\n",
    "results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Perform cross-validation or another approach in order to select\n",
    "the best degrees of freedom for a regression spline on this data.\n",
    "Describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 10 (p.300, Chap.7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question relates to the College data set.\n",
    "(a) Split the data into a training set and a test set. Using out-of-state\n",
    "tuition as the response and the other variables as the predictors,\n",
    "perform forward stepwise selection on the training set in order\n",
    "to identify a satisfactory model that uses just a subset of the\n",
    "predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/dwijayaweera/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'leaps' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\dwijayaweera\\AppData\\Local\\Temp\\RtmpekL8CQ\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'leaps' was built under R version 3.6.2\""
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in sample(length(Outstate), length(Outstate)/2): object 'Outstate' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in sample(length(Outstate), length(Outstate)/2): object 'Outstate' not found\nTraceback:\n",
      "1. sample(length(Outstate), length(Outstate)/2)"
     ]
    }
   ],
   "source": [
    "install.packages(\"leaps\")\n",
    "library(leaps)\n",
    "train = sample(length(Outstate), length(Outstate)/2)\n",
    "test = -train\n",
    "College.train = College[train, ]\n",
    "College.test = College[test, ]\n",
    "reg.fit = regsubsets(Outstate ~ ., data = College.train, nvmax = 17, method = \"forward\")\n",
    "reg.summary = summary(reg.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a GAM on the training data, using out-of-state tuition as\n",
    "the response and the features selected in the previous step as\n",
    "the predictors. Plot the results, and explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit = regsubsets(Outstate ~ ., data = College, method = \"forward\")\n",
    "coefi = coef(reg.fit, id = 6)\n",
    "names(coefi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Evaluate the model obtained on the test set, and explain the\n",
    "results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in predict(gam.fit, College.test): object 'gam.fit' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in predict(gam.fit, College.test): object 'gam.fit' not found\nTraceback:\n",
      "1. predict(gam.fit, College.test)"
     ]
    }
   ],
   "source": [
    "gam.pred = predict(gam.fit, College.test)\n",
    "gam.err = mean((College.test$Outstate - gam.pred)^2)\n",
    "gam.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in summary(gam.fit): object 'gam.fit' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in summary(gam.fit): object 'gam.fit' not found\nTraceback:\n",
      "1. summary(gam.fit)"
     ]
    }
   ],
   "source": [
    "summary(gam.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) For which variables, if any, is there evidence of a non-linear\n",
    "relationship with the response?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear relationship between response and Expend is displayed according to Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
